<!DOCTYPE html>
<html>
	<head>
		<link rel="stylesheet" type="text/css" href="style.css">
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
		<!-- <link rel="stylesheet" type="text/css" href="div_color.css"> -->
<!--		<link rel="stylesheet" type="text/css" href="ubuntu-style.css">
		<link href='http://fonts.googleapis.com/css?family=Ubuntu' rel='stylesheet' type='text/css'> -->

<!--		<link rel="stylesheet" type="text/css" href="grumpy-style.css">-->
<!--		<link href='http://fonts.googleapis.com/css?family=Shadows+Into+Light+Two' rel='stylesheet' type='text/css'>-->

<!--		<link rel="stylesheet" type="text/css" href="merri-style.css">-->
<!--		<link href='http://fonts.googleapis.com/css?family=Merriweather' rel='stylesheet' type='text/css'>-->

		<title>Jinming Su</title>
	</head>
	<body>
		<div id="container">
			<img src="img/sujinming.jpg" style="float: right" height="300px"/>
			<div id="header">

				<h1>
					Jinming Su(苏金明)
				</h1>

				<div class="mainText">
					<p style="text-indent:0">Email: sujinming0125@gmail.com</p>
					<p style="text-indent:0">Address: Beijing, China</p>
					<p style="text-indent:0">
						<a href="https://scholar.google.com/citations?hl=zh-CN&pli=1&user=Ouyg0iMAAAAJ">[Google Scholar]</a>
						<!--a href="./JinmingSu-CV.pdf">[CV]</a-->
						<a href="https://github.com/Jinming-Su">[Github]</a>
						<a href="https://www.zhihu.com/people/sjming">[知乎]</a>
					</p>
				</div>
			</div>
			<div id="menu">
				<ul>
					<a href="#news" id="newsButton"><li>News</li></a>
					<a href="#about" id="aboutButton" style="text-indent:2em"><li>About</li></a>
					<a href="#publications" id="pubButton" style="text-indent:2em"><li>Publications</li></a>
					<a href="#awards" id="awardsButton" style="text-indent:2em"><li>Awards</li></a>
					<!--a href="#patents" id="pubButton"><li>Patents</li></a-->
					<!--a href="#projects" id="honButton"><li>Projects</li></a-->
					<!--a href="#contact" id="contactButton"><li>Contact</li></a-->
					<!--a href="widget/ai_conference/conferences-with-ccf.html"><li>AI Conference</li></a-->
				</ul>
			</div>
<!-----------------------News---------------------------------------->
			<div class="mainText" id="news">
				<h3>News</h3>
				<!--p style="color:rgb(255,199,0)"><b>We are recruiting excellent self-motivated intern students. This is <a href='https://zhuanlan.zhihu.com/p/404037385'>JD</a>. Please contact me if you wish.</b></p-->
				<p style='color:red'><b>[2024-02-26] One paper on semi-supervised learning is accepted by CVPR 2024. </b></p>
				<p>[2023-06-12] We won the 1st place of Panoptic Segmentation & 1st place of Semantic Segmentation in the ACDC Workshop, CVPR 2023. </p>
				<p>[2023-06-09] We won the 3rd place of Video Panoptic Segmentation in the 2nd PVUW Workshop, CVPR 2023.</p>
				<p>[2023-03-31] Two papers (video object segmentation, instance segmentation) are accepted by the 2nd PVUW Workshop, CVPR 2023. </p>
				<p>[2022-10-11] We won the 2nd place of BDD100K Multiple Object Tracking in the 2nd SSLAD Workshop, ECCV 2022.</p>
				<p>[2022-10-08] We won the 1st place of Corner Case Detection in the 2nd SSLAD Workshop, ECCV 2022. </p>
				<p>[2022-06-19] We won the 5th place of Video Object Segmentation in the 4th Youtube-VOS Workshop, CVPR 2022.</p>
				<p>[2021-10-14] Code for IJCAI'21 SGNet are released [<a href="https://github.com/Jinming-Su/SGNet">Code</a>].</p>
				<p>[2021-10-14] Code for T-IP'21 PurNet are released [<a href="https://github.com/Jinming-Su/PurNet">Code</a>].</p>
				<p>[2021-10-13] Dataset and code for ICME'21 task-driven SOD (TSOD) are released [<a href="./projects/2021/ICME-TSOD/TSOD.html">Project</a>].</p>
				<p>[2021-07-04] One paper on foreground object segmentation is accepted by T-IP 2021.</p>
				<p>[2021-04-30] One paper on lane detection is accepted by IJCAI 2021.</p>
				<p>[2021-03-06] One paper on task-driven SOD is accepted as oral paper by ICME 2021.</p>
				<p>[2020-02-17] I join Meituan as an algorithm engineer.</p>
				<p>[2019-12-10] I pass my Master Dissertation defense.</p>
				<p>[2019-11-19] One paper on 360$^\circ$ SOD is accepted by J-STSP 2020.</p>
				<p>[2019-07-22] One paper on boundary-aware SOD is accepted by ICCV 2019.</p>
			</div>

			<div class="mainText" id="about">
                                <h3>About</h3>
                                <p>In 2020-2023, I worked as an algorithm engineer at <a href="https://about.meituan.com/home">Meituan</a> (北斗计划). </p>
				<!--p>I am broadly interested in solving real-world visual understanding problems with optimization/learning-based algorithms. Recently, I focus on developing learning and optimization frameworks for <b>2D/3D vision</b>.</p-->
				<p>I obtained my Master's degree (CS) in State Key Laboratory of Virtual Reality Technology and Systems, SCSE, Beihang University (BUAA), adviced by <a href="http://cvteam.net/members/lijia/upload/index.html">Prof. Jia Li</a> [<a href="http://cvteam.net/">CVTEAM</a>],  in Jan. 2020. From 2018 to 2019, I worked as research assistant at Peng Cheng Laboratory.</p> <!--p>Before that, I received Bachelor's degree (CS) from SCSE, Northeastern University (NEU), in Jul. 2017.</p-->
                        </div>

			<div class="mainText" >
				<h3>Research Interests</h3>
				<ul>
					<li><b>AIGC:</b> image generation/editing, 3D generation</li>
					<li><b>3D Vision:</b> 3D reconstruction, NeRF</li>
					<li><b>Autonomous Driving:</b> lane detection, depth estimation</li>
					<li><b>Scene Understanding:</b> image/video segmentation, multiple object tracking</li>
					<li><s><b>Visual Saliency:</b> salient object detection (SOD)</s></li>
				</ul>
			</div>

<!-----------------------Publications--------------------------------->
			<div class="mainText">
				<h3>Technical Reports</h3>
					<!--[<a href="https://scholar.google.com/citations?hl=zh-CN&pli=1&user=Ouyg0iMAAAAJ">Google Scholar</a>]</h3>	-->
				<!--div class="poster">
					<div class="poster-img">
						<img src="img/paper/2022_challenge_Youtube-VOS.png" style="max-width:300px;max-height:200px;"/>
					</div>
					<div class="poster-text">
						<h4>5th Place Solution for YouTube-VOS Challenge 2022: Video Object Segmentation.</h4>
						<i>Wangwang Yang*, <b>Jinming Su*</b>, Yiting Duan, Tingyi Guo and Junfeng Luo</i><br>
						[<a href="https://youtube-vos.org/assets/challenge/2022/reports/VOS_5th.pdf">PDF</a>][<a href="">arXiv</a>]
					</div>
				</div-->

				<div class="poster">
					<div class="poster-img">
						<img src="img/paper/2024_arxiv_Text2Street.png" style="max-width:280px;max-height:200px;"/>
					</div>
					<div class="poster-text">
						<h4>Text2Street: Controllable Text-to-image Generation for Street Views</h4>
						<i><b>Jinming Su*</b>, Songen Gu*, Yiting Duan, Xingyue Chen and Junfeng Luo</i><br>
						[<a href="https://arxiv.org/abs/2402.04504">arXiv</a>]
					</div>
				</div>



				<div class="poster">
					<div class="poster-img">
						<img src="img/paper/2022_arxiv_InsCon.png" style="max-width:280px;max-height:200px;"/>
					</div>
					<div class="poster-text">
						<h4>InsCon:Instance Consistency Feature Representation via Self-Supervised Learning.</h4>
						<i> Junwei Yang, Ke Zhang, Zhaolin Cui, <b>Jinming Su</b>, Junfeng Luo and Xiaolin Wei</i><br>
						[<a href="https://arxiv.org/abs/2203.07688">arXiv</a>]
					</div>
				</div>

				<div class="poster">
					<div class="poster-img">
						<img src="img/paper/RecNet.png" style="max-width:280px;max-height:200px;"/>
					</div>
					<div class="poster-text">
						<h4>Exploring Reciprocal Attention for Salient Object Detection by Cooperative Learning.</h4>
						<i> Changqun Xia, Jia Li, <b>Jinming Su</b> and Yonghong Tian.</i><br>
						[<a href="https://arxiv.org/abs/1909.08269">arXiv</a>]
					</div>
				</div>
				<div class="poster">
					<div class="poster-img">
						<img src="img/paper/CPS.png" style="max-width:280px;max-height:200px;"/>
					</div>
					<div class="poster-text">
						<h4>Learning a saliency evaluation metric using crowdsourced perceptual judgments.</h4>
						<i>Changqun Xia, Jia Li, <b>Jinming Su</b> and Ali Borji.</i><br>
						[<a href="https://arxiv.org/abs/1806.10257">arXiv</a>]
					</div>
				</div>

			</div>

			<div class="mainText" id="publications">
                		<h3>Publications</h3>
						<!-- [<a href="https://scholar.google.com/citations?hl=zh-CN&pli=1&user=Ouyg0iMAAAAJ">Google Scholar</a>]</h3> -->
				<div class="poster">
					<div class="poster-img">
						<img src="img/paper/2023_CVPRW_MSAF.png" style="max-width:280px;max-height:200px;"/>
					</div>
					<div class="poster-text">
						<h4>Motion-state Alignment for Video Semantic Segmentation.</h4>
						<i><b>Jinming Su*</b>, Ruihong Yin*, Shuaibin Zhang and Junfeng Luo. </i><br>
						<i>IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), 2023.</i>
						<b style="color: red">[CCF-A, Workshop Paper]</b>
						[<a href="https://openaccess.thecvf.com/content/CVPR2023W/PVUW/papers/Su_Motion-State_Alignment_for_Video_Semantic_Segmentation_CVPRW_2023_paper.pdf">PDF</a>]
						[<a href="https://arxiv.org/abs/2304.08820">arXiv</a>]
					</div>
				</div>


				<div class="poster">
					<div class="poster-img">
						<img src="img/paper/2023_CVPRW_PEP.png" style="max-width:280px;max-height:200px;"/>
					</div>
					<div class="poster-text">
						<h4>Perceive, Excavate and Purify: A Novel Object Mining Framework for Instance Segmentation.</h4>
						<i><b>Jinming Su</b>, Ruihong Yin, Xingyue Chen and Junfeng Luo. </i><br>
						<i>IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), 2023.</i>
						<b style="color: red">[CCF-A, Workshop Paper]</b>
						[<a href="https://openaccess.thecvf.com/content/CVPR2023W/PVUW/papers/Su_Perceive_Excavate_and_Purify_A_Novel_Object_Mining_Framework_for_CVPRW_2023_paper.pdf">PDF</a>]
						[<a href="https://arxiv.org/abs/2304.08826">arXiv</a>]
					</div>
				</div>

				<div class="poster">
					<div class="poster-img">
						<img src="img/paper/PurNet.png" style="max-width:280px;max-height:200px;"/>
					</div>
					<div class="poster-text">
						<h4>Salient Object Detection with Purificatory Mechanism and Structural Similarity Loss.</h4>
						<i>Jia Li, <b>Jinming Su</b>, Mingcan, Ma, Changqun Xia and Yonghong Tian. </i><br>
						<i>IEEE Transactions on Image Processing (T-IP), 30, pp.6855-6868, 2021.</i>
						<b style="color: red">[CCF-A, IF: 11.041]</b>
						[<a href="https://ieeexplore.ieee.org/document/9500052">PDF</a>]
						[<a href="https://arxiv.org/abs/1912.08393">arXiv</a>]
                        [<a href="https://github.com/Jinming-Su/PurNet">Github</a>]
					</div>
				</div>
				<div class="poster">
					<div class="poster-img">
						<img src="img/paper/2021_IJCAI_SGNet.png" style="max-width:280px;max-height:200px;"/>
					</div>
					<div class="poster-text">
						<h4>Structure Guided Lane Detection.</h4>
						<i><b>Jinming Su</b>, Chao Chen, Ke Zhang, Junfeng Luo, Xiaoming Wei and Xiaolin Wei.</i><br>
						<i>International Joint Conference on Artificial Intelligence (IJCAI), 2021.</i>
						<b style="color: red">[CCF-A]</b>
						[<a href="https://arxiv.org/abs/2105.05403">arXiv</a>]
						[<a href="https://mp.weixin.qq.com/s/1dwRw9u3mI9SGP-vqGHplQ">中文解读</a>]
						[<a href="https://github.com/Jinming-Su/SGNet">Github</a>]
					</div>
				</div>
				<div class="poster">
					<div class="poster-img">
						<img src="img/paper/2021_ICME_TSOD.png" style="max-width:280px;max-height:200px;"/>
					</div>
					<div class="poster-text">
						<h4>Exploring Driving-aware Salient Object Detection via Knowledge Transfer.</h4>
						<i><b>Jinming Su</b>, Changqun Xia and Jia Li. </i><br>
						<i>IEEE International Conference on Multimedia and Expo (ICME), 2021. (oral)</i>
						<b style="color: red">[CCF-B]</b>
						[<a href="https://ieeexplore.ieee.org/document/9428102">PDF</a>]
						[<a href="https://arxiv.org/abs/2105.08286">arXiv</a>]
						[<a href="./projects/2021/ICME-TSOD/TSOD.html">Project</a>]
					</div>
				</div>
				<div class="poster">
					<div class="poster-img">
						<img src="img/paper/360-SOD.png" style="max-width:280px;max-height:200px;"/>
					</div>
					<div class="poster-text">
						<h4>Distortion-adaptive Salient Object Detection in 360$^\circ$ Omnidirectional Images.</h4>
						<i>Jia Li, <b>Jinming Su</b>, Changqun Xia and Yonghong Tian.</i><br>
						<i>IEEE Journal of Selected Topics in Signal Processing (J-STSP), 14(1), pp.38-48, 2020.</i>
						<b style="color: red">[IF: 7.695]</b>
						[<a href="https://ieeexplore.ieee.org/document/8926489">PDF</a>]
						[<a href="https://arxiv.org/abs/2105.08286">Arxiv</a>]
						[<a href="./projects/2020/JSTSP-DDS/DDS.html">Project</a>]
					</div>
				</div>
				<div class="poster">
                                        <div class="poster-img">
                                                <img src="img/paper/BANet.png" style="max-width:280px;max-height:200px;"/>
                                        </div>
                                        <div class="poster-text">
                                                <h4>Selectivity or Invariance: Boundary-aware Salient Object Detection.</h4>
                                                <i><b>Jinming Su</b>, Jia Li, Yu Zhang, Changqun Xia and Yonghong Tian.</i><br>
                        			<i>IEEE International Conference on Computer Vision (ICCV), 2019.</i>
									<b style="color: red">[CCF-A]</b>
                                                [<a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Su_Selectivity_or_Invariance_Boundary-Aware_Salient_Object_Detection_ICCV_2019_paper.pdf">PDF</a>]
						[<a href="./projects/2019/ICCV-BANet/BANet.html">Project</a>]
                                        </div>
                                </div>
			</div>

<!-----------------------patents---------------------------------->
			<!--div class="mainText" id="patents">
                                <h3>Patents [<a href="http://www.soopat.com/Home/Result?Sort=&View=&Columns=&Valid=&Embed=&Db=&Ids=&FolderIds=&FolderId=&ImportPatentIndex=&Filter=&SearchWord=FMR%3A%28苏金明%29+&FMZL=Y">SooPAT</a>]</h3-->
				<!--ul>
					<li>李甲、<b>苏金明</b>、夏长群、赵沁平。一种图像显著对象分割方法及装置。申请日：2019年08月09日，申请号：201910732318.1. (In Application)</li>
                                	<li>李甲、<b>苏金明</b>、夏长群、赵沁平。图像前景物体分割方法及装置。申请日：2019年05月16日，申请号：201910407975.9. (In Application)</li>
					<li>李甲、<b>苏金明</b>、夏长群、赵一凡、赵沁平。一种图像前景物体分割方法。申请日：2018年12月24日，申请号：201811578893.2. (In Application)</li>
					<li>李甲、<b>苏金明</b>、夏长群、赵沁平。图像显著性预测结果的评价方法和装置。申请日：2018年05月14日，申请号：201810457947.3. (In Application)</li>
					<li>李甲、夏长群、<b>苏金明</b>、赵沁平。基于前背景相互关系的图像显著对象分割方法及装置。申请日：2019年05月21日，申请号：201910423491.3. (In Application)</li>
				</ul-->
<!-----------------------Projects--------------------------------->
			<!--div class="mainText" id="projects">
				<h3>Projects</h3>
				<p>I specialize in computer vision with deep/machine learning learning. In addition, I am interested in some engineering practices, especially some open source projects related to deep/machine learning. Moreover, I am also interested in basic computer algorithm, such as data structure, program optimization, etc.</p>
				<ul>
                    <li>A project for source code analysis of <i><b>Caffe</b></i>, which is helpful to understand the pipeline of Caffe running. <a href="https://github.com/Jinming-Su/caffe-source-code-analysis">[Github]</a></li>
					<li>A public <i><b>learning_note</b></i> on computer vision is under construction, including mathematics, machine learning and deep learning. This note will solve many difficult derivation problems.<a href="https://github.com/Jinming-Su/learning_notes/blob/master/note.pdf">[Github]</a></li>
					<li>A web application on <i><b>salient object detection (SOD) of 360$^\circ$ omnidirectional images</b></i> will be publicly available. In this project, everyone can upload omnidirectional images, browse images by drgging as well as prediction of SOD of these images on any platform with a browser.<a style="color: red">[Release later]</a></li>
					<li>An <i><b>old blog</b></i> for anything related to computer science can be found, which has 300+ posters written from 2014 to 2018. I will reorganize this blog if I have time later.<a href="https://blog.csdn.net/u014451076">[Csdn blog]</a></li>
				</ul>
			</div-->
<!-----------------------education------------------------------->
			<!--div class="mainText">
                        <h3>Education</h3>
                		<div class="poster">
                                        <div class="poster-img">
                                                <img src="img/beihang.jpg" style="max-width:300px;max-height:200px;"/>
                                        </div>
                                        <div class="poster-text">
                        	<h4>Beihang University (BUAA), Beijing, China</h4>
                                                 2017 - 2020 <br>
                                                <i><b>M.Sc.</b></i> in Computer Science and Technology, ranked 9/303 (top 5%) <br>
                                                - State Key Laboratory of Virtual Reality Technology and Systems, SCSE <br>
						- Dissertation: 场景和任务引导的图像显著内容解析</br>
						- Advisor: <a href="http://cvteam.net/members/lijia/upload/index.html">Jia Li</a> [<a href="http://cvteam.net/">CVTEAM</a>] </br>
                                        </div>
                                </div>
				</br>
                                <div class="poster">
                                        <div class="poster-img">
                                                <img src="img/neu.png" style="max-width:300px;max-height:200px;"/>
                                        </div>
                                        <div class="poster-text">
                                                <h4>Northeastern University (NEU), Shenyang, China</h4>
                                                2013 - 2017 <br>
                                                <i><b>B.Eng.</b></i> in Computer Science and Technology, ranked 10/258 (top 5%) <br>
                                                - Dissertation: 基于移动终端的室外场景语义分割方法与系统<br>
                                                - Recommended for admission to Beihang University without exams <br>
                                        </div>
                                </div>
                        </div-->
<!-----------------------honors---------------------------------->
			<div class="mainText" >
				<h3>Selected Competitions</h3>
				<ul>
					<li>1st place of Panoptic Segmentation in the ACDC Workshop, CVPR 2023</li>
					<li>1st place of Semantic Segmentation in the ACDC Workshop, CVPR 2023</li>
					<li>3rd place of Video Panoptic Segmentation in the 2nd PVUW Workshop, CVPR 2023</li>
					<!--li>6th place of Video Semantic Segmentation in the 2nd PVUW Workshop, CVPR 2023</li-->
					<li>2nd place of BDD100K Multiple Object Tracking in the 2nd SSLAD Workshop, ECCV 2022</li>
					<li>1st place of Corner Case Detection in the 2nd SSLAD Workshop, ECCV 2022</li>
					<li>5th place of Video Object Segmentation in the 4th Youtube-VOS Workshop, CVPR 2022</li>
					<li>2nd prize of the National English Competition for College Students, 2015</li>
					<li>1st prize of the Liaoning Province ACM-ICPC Contest, 2015</li>
					<li>1st prize of the Liaoning Province ACM-ICPC Contest, 2014</li>
					<li>2nd prize of the China Undergraduate Mathematical Contest in Modeling, 2014</li>
					<li>1st prize of the Liaoning Province Undergraduate Mathematical Contest in Modeling, 2014</li>
					<li>3rd prize of the Northeast Region ACM-ICPC Contest, 2014</li>
				</ul>
			</div>
			<div class="mainText" id="awards">
				<h3>Selected Honors and Awards</h3>
				<ul>
					<li>Star of Basic Research & Development Business Group (10 of 2000+), in Meituan, 2022</li>
					<li>Meituan Academic Innovation Award (team award), in Meituan, 2021</li>
					<li>Star of Intelligent Traffic Business Group (39 of 2000+), in Meituan, 2021</li>
					<li>Outstanding Master Graduate of Beijing City, 2020</li>
					<li>Outstanding Master Graduate Thesis of Beihang University, 2020</li>
					<li>National Scholarship, 2019</li>
					<li>Huawei Scholarship, 2019</li>
					<li>Outstanding Student of Beihang University, 2019</li>
					<li>Merit Student of Beihang University, 2018/2019
					<li>Outstanding Undergraduate Thesis of Northeastern University, 2017</li>
					<li>National Encouragement Scholarship, 2014/2015/2016</li>
					<li>Excellent Student of Northeastern University, 2014/2015</li>
					<li>Outstanding Innovation Individual of Northeastern University, 2014
					<li>The Zhou Kun Scholarship, 2013/2014/2015/2016</li>
				</ul>
			</div>
			<div class="mainText" >
				<h3>Services and Activities</h3>
				<ul>
					<li>Reviewer for journals: T-PAMI, T-IP, T-CSVT, T-IV</li>
					<li>Reviewer for conferences: CVPR, ICCV, ECCV</li>
					<li>Tech blog on "美团技术团队" WeChat public platform, 2023 [<a href="https://mp.weixin.qq.com/s/Jk0EGvtrtogR1bdpNMmtgg">URL</a>]</li>
					<li>Oral presentation in ACDC Workshop, CVPR 2023 [<a href="https://vision4allseason.net/program-2/">URL</a>]</li>
					<li>Oral presentation in PVUW Workshop, CVPR 2023 [<a href="https://arxiv.org/abs/2306.06753">PDF</a>]</li>
					<li>Oral presentation on "AI TIME" WeChat public platform, 2022 [<a href="https://www.bilibili.com/video/BV1K44y1E7aT/?spm_id_from=333.337.search-card.all.click&vd_source=2a3c0287dbbf798364ea09b37b8511c5">URL</a>]</li>
					<li>Poster presentation in Youtube-VOS Workshop, CVPR 2022 [<a href="https://youtube-vos.org/challenge/2022/leaderboard/">URL</a>]</li>
					<li>Tech blog on "机器之心" WeChat public platform, 2021 [<a href="https://mp.weixin.qq.com/s/1dwRw9u3mI9SGP-vqGHplQ">URL</a>]</li>
					<li>Poster presentation in VALSE 2021 [<a href="http://valser.org/2021/static/poster/098.pdf">Poster</a>]</li>
				</ul>
			</div>
<!-----------------------contact--------------------------------->
			<!--div class="mainText" id="contact">
				<h3>Contact</h3>
				<p>Email: sujinming@meituan.com</p>
                		<p>Github: <a href="https://github.com/Jinming-Su">https://github.com/Jinming-Su</a></p>
				<p>Zhihu: <a href="https://www.zhihu.com/people/sjming">https://www.zhihu.com/people/sjming</a></p>
			</div-->
			<!--div class="mainText" id="link">
				<h3>Link</h3>
				<p><a href='https://jackietseng.github.io/conference_call_for_paper/conferences-with-ccf.html'>International Conferences Time</a></p>
			</div-->
<!-----------------------former interns--------------------------------->
			<div class="mainText" id="former_intern">
				<h3>Former Interns</h3>
				<ul>
					<li style="font-size:15px;"><b>Chao Chen</b> (IJCAI 2021), master student from Beihang University, intership 2020-2021. Now he is an engineer at ByteDance.</li>
					<li style="font-size:15px;"><b>Ruihong Yin</b> (CVPRW 2023), master student from Beihang University, intership 2020-2021. Now she is a PhD student at the University of Amsterdam.</li>
					<li style="font-size:15px;"><b>Shuaibin Zhang</b> (CVPRW 2023), master student from University of Chinese Academy of Sciences, intership 2021. Now he is an engineer at Baidu.</li>
					<li style="font-size:15px;"><b>Rui Ren</b> (image editing), master student from Xidian University, intership 2023. He will join Meituan as an engineer in 2024.</li>
					<li style="font-size:15px;"><b>Songen Gu</b> (image generation), master student from University of Chinese Academy of Sciences, intership 2023.</li>
				</ul>
			</div>
	
		</div>

		<script type="text/javascript" src="script.js"></script>

	</body>
</html>
